{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e780f4-ac92-4e4a-97fc-a192b3786ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fccaa0-1af5-4c0e-b2c4-7e770bd09663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_run_metrics, read_run_dir, get_model_from_run\n",
    "from plot_utils import basic_plot, collect_results, relevant_model_names\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682c7379-a295-4131-a25e-2f790e8c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [f'cuda:{i}' for i in range(torch.cuda.device_count())]\n",
    "device = devices[1] # use GPU #1 on the machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2421a-fa02-437d-9539-a136b5cace8a",
   "metadata": {},
   "source": [
    "### In-Context Learning (ICL) for Transformers\n",
    "A Transformer $T$ takes in a sequence and generate a prediction. In our case, each sequence represents a learning task with varying underlying oracle functions.\n",
    "\n",
    "Suppose we have a Tranformer $T$ trained with in-context-learning objective on linear functions, i.e., each sequence is generated as follows:\n",
    "1. $w \\sim \\mathcal{N}(0,I)$\n",
    "2. For $i= 1, \\dots, n$:\n",
    "       $x_i \\sim \\mathcal{N}(0,I), y_i = w^{\\top}x_i$\n",
    "The Transformers $T$ is trained to take in the sequence $\\{x_1,y_1,x_2,y_2,\\dots,x_n\\}$ and predicts $y_n$.\n",
    "\n",
    "### Transferring the Knowledge within the Transformers\n",
    "\n",
    "We consider the **offline** contextual bandit problem where we are given an offline dataset $D=\\{(s_i,a_i,r_i)\\}_{i=1}^n$. The actions $a_i$'s were collected by an unknown behavirol policy. Each task is characterized by a state distribution $P_S$, and a reward function \n",
    "$r = f(s,a)$. We first focus on the linear contextual bandit problem with\n",
    "$$\n",
    "r = f(s,a) =\\theta^{*\\top} \\phi(s,a)\n",
    "$$\n",
    "where $\\phi(s,a):\\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathbb{R}^d$ is the feature function. \n",
    "\n",
    "#### Comparison with the regular MDP setting\n",
    "In the offline RL setting considered by the Decision Transformer, we have a set of trajectories $D=\\{\\tau_j = (s_0,a_0,r_0,s_1,a_1,r_1,\\dots)\\}_{j=1}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ad89d-74cf-4980-999d-5d15c50f9de2",
   "metadata": {},
   "source": [
    "### Loading Trained Transformer\n",
    "\n",
    "The trained Transformer has input dimension $20$ and generate scalar ouputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5b296c-fccb-4dcf-96e8-6367bd443169",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"linear_regression\"\n",
    "#task = \"sparse_linear_regression\"\n",
    "#task = \"decision_tree\"\n",
    "#task = \"relu_2nn_regression\"\n",
    "\n",
    "run_id = \"pretrained\"  # if you train more models, replace with the run_id from the table above\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "\n",
    "model, conf = get_model_from_run(run_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b9d74f-11a5-47c7-806c-31bc3f71d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.randn(10,40,20).to(device) # randomly generate 10 ICL tasks, each one with 40 instances and X has dimension 20\n",
    "ys = torch.randn(10,40).to(device) # randomly generate regression labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32675811-19db-428d-ba92-9e32c7af229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,pred = model(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3856c5b6-f54f-4bbb-8a79-f44ea1258915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353cdf2-5aaf-4434-99f3-0454ff8aeff1",
   "metadata": {},
   "source": [
    "### ICL for Contextual Bandits\n",
    "\n",
    "We consider the case where $\\phi$ is a linear function, i.e., \n",
    "$$\n",
    "\\begin{align}\n",
    "&\\phi(s,a) = As + Ba,\\\\\n",
    "& r = \\theta^{*\\top}As + \\theta^{*\\top}Ba\n",
    "\\end{align}\n",
    "$$\n",
    "Another reward function choice can be \n",
    "$$\n",
    "r = s^{\\top}Aa\n",
    "$$\n",
    "Assume that $\\theta^* \\sim \\mathcal{N}(0,I)$ and $A,B \\sim \\mathcal{N}(0,1)$ elementwise. Different tuples of $(\\theta^*, A, B)$ defines different contextual bandits problems.\n",
    "\n",
    "The expected return of an action $a$ is \n",
    "$$\n",
    "R(a) = \\mathbb{E}[r|a] = \\mathbb{E}[\\theta^{*\\top}\\phi(s,a)] = \\theta^{*\\top}Ba.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7291b348-61d4-43f2-828c-adf065059f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d20ab3-4e7f-4e59-b3e1-c92cffc031db",
   "metadata": {},
   "source": [
    "### Using varying bandit problems for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2490a563-71e8-4bbd-8e21-2ab9db82d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Offline dataset with varying contextual bandits problems\n",
    "S_DIM = 5 # dimension of states\n",
    "A_NUM = 5 # total number of actions (bandits)\n",
    "\n",
    "def reward_function(s,a,theta,Ms,Ma):\n",
    "    '''\n",
    "    Linear reward function\n",
    "    '''\n",
    "    r = theta@Ms@s + theta@Ma@a\n",
    "    return r\n",
    "\n",
    "def generate_ICL_seqs(num_ICL, num_instances, s_dim=20, a_num = 100, optimal_scale=0.8):\n",
    "    # Ss, As, Rs = [], [], []\n",
    "    ICL_seqs = []\n",
    "    for _ in tqdm(range(num_ICL)):\n",
    "        # generate a new contextual bandits problem\n",
    "        theta = torch.randn(20)*0.1\n",
    "        Ms = torch.randn(20,s_dim)*0.1\n",
    "        Ma = torch.randn(20,a_num)*0.1\n",
    "        # find optimal action and define behaviral policy \n",
    "        optimal_action = torch.argmax(theta@Ma).item()\n",
    "        if optimal_scale:\n",
    "            probs = torch.tensor([(1-optimal_scale)/a_num]*a_num)\n",
    "            probs[optimal_action] += optimal_scale\n",
    "        else: # if no optimal_scale, use a uniform policy as behaviral policy \n",
    "            probs = torch.tensor([1/a_num]*a_num)\n",
    "        b_policy = torch.distributions.categorical.Categorical(probs)\n",
    "\n",
    "        D = []\n",
    "        for i in range(num_instances):\n",
    "            new_s = torch.randn(s_dim) # sample a new state\n",
    "            new_a = b_policy.sample()  # perform an action with behaviral policy \n",
    "            new_a = nn.functional.one_hot(new_a,num_classes=a_num).float()\n",
    "            new_r = reward_function(new_s,new_a,theta, Ms,Ma) # receive a reward \n",
    "            D.append((new_s,new_a,new_r))\n",
    "        S, A, R = torch.stack([t[0] for t in D],dim=0), torch.stack([t[1] for t in D],dim=0), torch.stack([t[2] for t in D],dim=0)\n",
    "\n",
    "        ICL_seqs.append((S,A,R,nn.functional.one_hot(torch.tensor(optimal_action),num_classes=a_num).float()))\n",
    "    return ICL_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a14df7f-67ca-4586-ba03-dfc710e67d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Offline dataset\n",
    "# Number of actions: 100\n",
    "# Distribution of states:Gaussian(0,I_20)\n",
    "# Behaviral policy: uniformly random policy\n",
    "s_dim = 20\n",
    "a_num = 100\n",
    "\n",
    "theta = torch.randn(20)\n",
    "Ms = torch.randn(20,s_dim)\n",
    "Ma = torch.randn(20,a_num)\n",
    "def reward_function(s,a):\n",
    "    '''\n",
    "    Linear reward function\n",
    "    '''\n",
    "    r = theta@Ms@s + theta@Ma@a\n",
    "    return r\n",
    "\n",
    "def generate_offline_dataset(num,s_dim,a_num):\n",
    "    uniform_policy = torch.distributions.categorical.Categorical(torch.tensor([1/a_num]*a_num))\n",
    "    dataset = []\n",
    "    for _ in range(num):\n",
    "        new_s = torch.randn(s_dim)\n",
    "        new_a = uniform_policy.sample()\n",
    "        new_a = nn.functional.one_hot(new_a,num_classes=a_num).float()\n",
    "        new_r = reward_function(new_s,new_a)\n",
    "        dataset.append((new_s,new_a,new_r))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6857482d-b775-4947-a613-437099e82d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best bandit index: tensor(88)\n"
     ]
    }
   ],
   "source": [
    "# Oracle Best Bandit\n",
    "print('Best bandit index:', torch.argmax(theta@Ma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a10591d-9d11-4e40-84bf-8a69793ea13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 20]), torch.Size([1000, 100]), torch.Size([1000]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = generate_offline_dataset(num=1000,s_dim=s_dim,a_num=a_num)\n",
    "S, A, R = torch.stack([t[0] for t in D],dim=0), torch.stack([t[1] for t in D],dim=0), torch.stack([t[2] for t in D],dim=0)\n",
    "S.shape, A.shape, R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68c1eb49-262d-4537-bf85-f7f7684044e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the given n data instances, each time we randomly sample m out of them, we repeat this for k times to construct k ICL sequences\n",
    "def generate_ICL_sequences(S,A,R,num_ICL,num_instances):\n",
    "    total_num = S.shape[0]\n",
    "    ICL_sequences = []\n",
    "    for _ in range(num_ICL):\n",
    "        indices = np.random.choice(range(total_num),num_instances,replace=False)\n",
    "        ICL_sequences.append((S[indices],A[indices],R[indices]))\n",
    "    return ICL_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39a35f67-b278-465c-82d0-9432252e3bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 50, 21]), torch.Size([2000, 50, 100]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICLs = generate_ICL_sequences(S,A,R,2000,50)\n",
    "ICL_X = torch.cat([torch.stack([t[0] for t in ICLs],dim=0),torch.stack([t[2] for t in ICLs],dim=0).unsqueeze(2)],dim=-1)\n",
    "ICL_Y = torch.stack([t[1] for t in ICLs],dim=0)\n",
    "ICL_X.shape, ICL_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74f0b2-f61a-4112-8c4e-d6ea95e4adc5",
   "metadata": {},
   "source": [
    "### Dataset Generation\n",
    "\n",
    "Decision Transformer (DT)-based methods address RL as sequence modeling problem, at time step $t$, the input is the realized trajectory so far $\\tau_t = (s_1,a_1,r_1,s_2,a_2,r_2,\\dots,s_t)$ and a signal called returns-to-go (RTG) $R_t$ which represents the rewards to receive, the ouput $a_t$ is the predicted act that can lead to $R_t$.\n",
    "\n",
    "To frame offline contextual bandit as ICL problem, we would like construct a sequence of $(X,y)$'s and an individual $X'$ whose $y$ is the target for prediction. Recall the offline dataset for contextual bandits $D=\\{S_i,A_i,R_i\\}$. To this end, we let $X = [S,R]$ and $Y = A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e414a424-ebca-4a66-986d-e1b74880abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9bda5c8-25a9-4ea3-8cbb-6c02bc48b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007051706314086914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30efbb713de410781c50648a77ea732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 100, 6]), torch.Size([10000, 100, 5]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ICL = 10000 # generate 50k contextual bandits problems\n",
    "num_instances = 100 # each offline dataset has 100 samples\n",
    "\n",
    "# generate_ICL_seqs will return offline datasets for num_ICL different tasks\n",
    "# [ICL_1, ICL_2, ICL_3, ..., ICL_{num_ICL}]\n",
    "# where ICL_i = [S, A, R]\n",
    "# S has dimension (num_instances x s_dim)\n",
    "# A has dimension (num_instances x a_num)\n",
    "# R has dimension (num_instances x 1) \n",
    "\n",
    "ICL_seqs = generate_ICL_seqs(num_ICL, num_instances, s_dim = S_DIM, a_num = A_NUM, optimal_scale=0.7)\n",
    "\n",
    "# X = [S,R], Y = A\n",
    "ICL_X = torch.cat([torch.stack([t[0] for t in ICL_seqs],dim=0),torch.stack([t[2] for t in ICL_seqs],dim=0).unsqueeze(2)],dim=-1)\n",
    "ICL_Y = torch.stack([t[1] for t in ICL_seqs],dim=0)\n",
    "ICL_Y_opt = torch.stack([t[3] for t in ICL_seqs],dim=0)\n",
    "\n",
    "ICL_X.shape, ICL_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "854ff8b1-8f21-4450-87c8-cf2685eabe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConBanDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ICL_X = self.X[idx]\n",
    "        ICL_Y = self.Y[idx]\n",
    "        \n",
    "        return ICL_X, ICL_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe08df3f-5421-45e9-9253-07b465c66ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num_ICL = 32 # each batch has 32 contextual bandits problems\n",
    "tr_dataset = ConBanDataset(ICL_X, ICL_Y)\n",
    "tr_loader = DataLoader(tr_dataset, batch_num_ICL, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2807cd-5f21-491d-9ec3-f9b01365595c",
   "metadata": {},
   "source": [
    "## Train a TF from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3506d7-7cbd-44bd-9cf8-48594855eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "from models import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "191cb17f-9840-41af-bca1-dba02b629e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_hidden=5):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(input_dim, hidden_dim)] \\\n",
    "                                     +[nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)]\\\n",
    "                                     +[nn.Linear(hidden_dim, output_dim)])\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linears[0](x)\n",
    "        for linear in self.linears[1:-1]:\n",
    "            x = x + linear(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.linears[-1](x)\n",
    "        return x\n",
    "\n",
    "class ICL_learner(nn.Module):\n",
    "    def __init__(self,dim_states, n_action, n_positions=501, n_embd=256, n_layer=12, n_head=8):\n",
    "        super(ICL_learner, self).__init__()\n",
    "        # Backbone is a GPT2 model\n",
    "        self._backbone = TransformerModel(n_dims = dim_states+1, n_positions=n_positions, n_embd=n_embd, n_layer=n_layer, n_head=n_head)\n",
    "        self._action_encoder = ResNet(n_action,hidden_dim=128,output_dim = dim_states+1, num_hidden=3)\n",
    "        self._readout = nn.Linear(n_embd,n_action)\n",
    "    def forward(self,raw_x, raw_y):\n",
    "        \n",
    "        c_x = raw_x \n",
    "        c_y = self._action_encoder(raw_y)\n",
    "        bsize, points, dim = c_x.shape\n",
    "        \n",
    "        zs = torch.stack([c_x,c_y],dim=2)\n",
    "        zs = zs.view(bsize,2*points,dim)\n",
    "        # print(zs.shape)\n",
    "\n",
    "        # embed = model._read_in(zs)\n",
    "        embed = self._backbone._read_in(zs)\n",
    "        output = self._backbone._backbone(inputs_embeds = embed).last_hidden_state\n",
    "        # output = self._backbone(zs).last_hidden_state\n",
    "        pred = self._readout(output)\n",
    "        # pred = self.softmax(pred)\n",
    "        \n",
    "        return output, pred[:,::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc1826e8-091c-4fb9-b21c-5c61e84ddc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = ICL_learner(S_DIM, A_NUM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a488f9c4-3deb-444b-b655-385bff28e99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004308938980102539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de44f1f0530488b8b9e903685648b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0...\n",
      "loss: 92.16751861572266\n",
      "loss: 92.103271484375\n",
      "loss: 92.10306549072266\n",
      "loss: 92.10340881347656\n",
      "loss: 92.10343933105469\n",
      "loss: 92.10356903076172\n",
      "loss: 92.10282135009766\n",
      "EPOCH 1...\n",
      "loss: 92.103515625\n",
      "loss: 92.1039047241211\n",
      "loss: 92.0979995727539\n",
      "loss: 92.02251434326172\n",
      "loss: 92.1231689453125\n",
      "loss: 92.1375732421875\n",
      "loss: 92.0184326171875\n",
      "EPOCH 2...\n",
      "loss: 92.04609680175781\n",
      "loss: 92.00853729248047\n",
      "loss: 92.0137710571289\n",
      "loss: 91.99898529052734\n",
      "loss: 92.08428955078125\n",
      "loss: 91.97474670410156\n",
      "loss: 91.82493591308594\n",
      "EPOCH 3...\n",
      "loss: 91.9023666381836\n",
      "loss: 91.59791564941406\n",
      "loss: 91.93990325927734\n",
      "loss: 91.5851058959961\n",
      "loss: 91.07327270507812\n",
      "loss: 91.07305145263672\n",
      "loss: 90.59034729003906\n",
      "EPOCH 4...\n",
      "loss: 90.48949432373047\n",
      "loss: 90.47530364990234\n",
      "loss: 90.20228576660156\n",
      "loss: 90.1248779296875\n",
      "loss: 89.96210479736328\n",
      "loss: 90.10002899169922\n",
      "loss: 90.1965560913086\n",
      "EPOCH 5...\n",
      "loss: 89.99669647216797\n",
      "loss: 90.02967834472656\n",
      "loss: 90.0966567993164\n",
      "loss: 90.10198211669922\n",
      "loss: 89.8756103515625\n",
      "loss: 90.1546859741211\n",
      "loss: 89.93229675292969\n",
      "EPOCH 6...\n",
      "loss: 90.0230941772461\n",
      "loss: 89.86357879638672\n",
      "loss: 89.7472152709961\n",
      "loss: 89.96510314941406\n",
      "loss: 90.04195404052734\n",
      "loss: 89.99390411376953\n",
      "loss: 89.84308624267578\n",
      "EPOCH 7...\n",
      "loss: 89.91844177246094\n",
      "loss: 89.76348114013672\n",
      "loss: 89.89588928222656\n",
      "loss: 90.44778442382812\n",
      "loss: 90.16643524169922\n",
      "loss: 90.31085205078125\n",
      "loss: 90.46198272705078\n",
      "EPOCH 8...\n",
      "loss: 90.29302978515625\n",
      "loss: 89.87003326416016\n",
      "loss: 89.87761688232422\n",
      "loss: 90.43392181396484\n",
      "loss: 90.34126281738281\n",
      "loss: 90.37291717529297\n",
      "loss: 90.17405700683594\n",
      "EPOCH 9...\n",
      "loss: 90.1649398803711\n",
      "loss: 90.12482452392578\n",
      "loss: 90.19448852539062\n",
      "loss: 89.94925689697266\n",
      "loss: 90.21971893310547\n",
      "loss: 89.99739837646484\n",
      "loss: 90.0107650756836\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "loss = nn.CrossEntropyLoss() # cross-entropy loss for bandit identification\n",
    "optimizer = torch.optim.Adam([param for param in adapter.parameters() if param.requires_grad == True],lr=1e-4)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'EPOCH {epoch}...')\n",
    "    for batch_idx, (batch_x,batch_y) in enumerate(tr_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # shuffle the order of ICL instances \n",
    "        # shuffle_idx = torch.randperm(50)\n",
    "        # batch_x = batch_x[:,shuffle_idx,:]\n",
    "        # batch_y = batch_y[:,shuffle_idx,:]\n",
    "        _,pred = adapter(batch_x.to(device),batch_y.to(device))\n",
    "        # pred_bandit = torch.argmax(pred,dim=-1)\n",
    "        l = loss(pred[:,:,:].softmax(dim=-1), batch_y[:,:,:].to(device))\n",
    "        l.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "\n",
    "        # report every 50 steps\n",
    "        if batch_idx% 50 == 0: \n",
    "            # print(torch.norm(adapter.linear_x.weight.grad))\n",
    "            # print('selected bandits:',pred_bandit)\n",
    "            print(\"loss:\",l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8eb47fd0-4059-4f3b-b029-e9dac4b19d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adapter, '../models/ICL_tfs_10000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a853cac-6717-4d94-a291-f6a4bcd7c00a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Try setting all the target actions are optimal actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b822927e-6fe0-4868-b0a3-49d5d827e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num_ICL = 32 # each batch has 32 contextual bandits problems\n",
    "tr_dataset = ConBanDataset(ICL_X, torch.cat([ICL_Y_opt.unsqueeze(1)]*num_instances,dim=1))\n",
    "tr_loader = DataLoader(tr_dataset, batch_num_ICL, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52da4c-d6a9-43c4-9ae5-35f02c52abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training \n",
    "loss = nn.CrossEntropyLoss() # cross-entropy loss for bandit identification\n",
    "optimizer = torch.optim.Adam([param for param in adapter.parameters() if param.requires_grad == True],lr=1e-4)\n",
    "\n",
    "EPOCHS = 2\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'EPOCH {epoch}...')\n",
    "    for batch_idx, (batch_x,batch_y) in enumerate(tr_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # shuffle the order of ICL instances \n",
    "        # shuffle_idx = torch.randperm(50)\n",
    "        # batch_x = batch_x[:,shuffle_idx,:]\n",
    "        # batch_y = batch_y[:,shuffle_idx,:]\n",
    "        _,pred = adapter(batch_x.to(device),batch_y.to(device))\n",
    "        # pred_bandit = torch.argmax(pred,dim=-1)\n",
    "        l = loss(pred[:,:,:].softmax(dim=-1), batch_y[:,:,:].to(device))\n",
    "        l.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "\n",
    "        # report every 200 steps\n",
    "        if batch_idx%50 == 0: \n",
    "            # print(torch.norm(adapter.linear_x.weight.grad))\n",
    "            # print('selected bandits:',pred_bandit)\n",
    "            print(\"loss:\",l.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe8567-a599-4e41-9c64-4625eff36022",
   "metadata": {},
   "source": [
    "## Adapt From A Trained ICL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57bbab6-d380-49b5-ad21-dc5cfcf41b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICL_adapter(nn.Module):\n",
    "    def __init__(self, base_model, x_dim, y_dim,pred_dim,hidden_dim=256):\n",
    "        # Note that pred_dim should be equal to y_dim\n",
    "        super(ICL_adapter, self).__init__()\n",
    "        self.linear_x = nn.Linear(x_dim,hidden_dim)\n",
    "        self.linear_y = nn.Linear(y_dim,hidden_dim)\n",
    "        self.converter_x = ResNet(hidden_dim, hidden_dim, conf.model.n_dims).to(device) #Input dim to trained TF: conf.model.n_dims = 20\n",
    "        self.converter_y = ResNet(hidden_dim, hidden_dim, conf.model.n_dims).to(device)\n",
    "        self.base_model = base_model\n",
    "        # self.readout = ResNet(256,256,pred_dim,num_hidden=3)\n",
    "        self.readout = nn.Linear(256,pred_dim)\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "       \n",
    "\n",
    "    def forward(self,raw_x, raw_y):\n",
    "        ## c_x and c_y needs to have the same shape after converter mapping!\n",
    "        c_x, c_y = self.linear_x(raw_x), self.linear_y(raw_y)\n",
    "        # non-linear transformation\n",
    "        c_x, c_y = self.converter_x(c_x),self.converter_y(c_y)\n",
    "\n",
    "        bsize, points, dim = c_x.shape\n",
    "        zs = torch.stack([c_x,c_y],dim=2)\n",
    "        zs = zs.view(bsize,2*points,dim)\n",
    "\n",
    "        embed = model._read_in(zs)\n",
    "        output = model._backbone(inputs_embeds = embed).last_hidden_state\n",
    "        pred = self.readout(output)\n",
    "        # pred = self.softmax(pred)\n",
    "        \n",
    "        return output, pred[:,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7ce541ba-dbc0-47f7-9751-e0c50e027b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with Trained Transformers\n",
    "model, conf = get_model_from_run(run_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70e59945-23c6-4bca-9325-ca8fc742386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the trained ICL model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "adapter = ICL_adapter(model, x_dim = s_dim + 1, y_dim = a_num, pred_dim=a_num,hidden_dim=256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee3770-f130-4b1b-ad52-568e65a2c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training \n",
    "loss = nn.CrossEntropyLoss() # cross-entropy loss for bandit identification\n",
    "optimizer = torch.optim.Adam([param for param in adapter.parameters() if param.requires_grad == True],lr=1e-4)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'EPOCH {epoch}...')\n",
    "    for batch_idx, (batch_x,batch_y) in enumerate(tr_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # shuffle the order of ICL instances \n",
    "        # shuffle_idx = torch.randperm(50)\n",
    "        # batch_x = batch_x[:,shuffle_idx,:]\n",
    "        # batch_y = batch_y[:,shuffle_idx,:]\n",
    "        _,pred = adapter(batch_x.to(device),batch_y.to(device))\n",
    "        # pred_bandit = torch.argmax(pred,dim=-1)\n",
    "        l = loss(pred[:,:,:].softmax(dim=-1), batch_y[:,:,:].to(device))\n",
    "        l.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "\n",
    "        # report every 200 steps\n",
    "        if batch_idx%50 == 0: \n",
    "            # print(torch.norm(adapter.linear_x.weight.grad))\n",
    "            # print('selected bandits:',pred_bandit)\n",
    "            print(\"loss:\",l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c728c01c-dee0-4d5e-bf0e-a8aec27063aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adapter, '../models/ICL_adapter_10000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4d19b-c344-4068-985d-33ff375160e4",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84f7d3c6-ce7f-4752-b874-ec87bf92e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,input_r=None, horizon=100):\n",
    "    # generate a new contextual bandit instance\n",
    "    theta = torch.randn(20)*0.1\n",
    "    Ms = torch.randn(20,s_dim)*0.1\n",
    "    Ma = torch.randn(20,a_num)*0.1\n",
    "    \n",
    "    # calculate the expected return of all the bandits \n",
    "    bandit_values = theta@Ma\n",
    "    optimal_value = max(bandit_values).item()\n",
    "    worst_value = min(bandit_values).item()\n",
    "    # print('best bandit:', torch.argmax(bandit_values).item())\n",
    "    # print('best reward:', optimal_value)\n",
    "    if input_r is None:\n",
    "        input_r = optimal_value\n",
    "    \n",
    "    \n",
    "    selected_bandits = []\n",
    "    s=[]\n",
    "    new_a = torch.distributions.categorical.Categorical(torch.tensor([1/a_num]*a_num)).sample()\n",
    "    new_a = nn.functional.one_hot(new_a,num_classes=a_num).float().to(device)\n",
    "    a=[new_a] #dummy first action\n",
    "    r=[] \n",
    "    \n",
    "    for _ in range(horizon):\n",
    "        # encounter a new state\n",
    "        new_s = torch.randn(s_dim)\n",
    "        s.append(new_s)\n",
    "        if len(r) > 0:\n",
    "            r[-1] = new_r\n",
    "        r.append(torch.tensor(input_r))\n",
    "        # construct inputs\n",
    "        r = r[-50:]\n",
    "        s = s[-50:]\n",
    "        a = a[-50:]\n",
    "        input_x = torch.cat([torch.stack(s,dim=0),torch.stack(r,dim=0).unsqueeze(-1)],dim=-1).unsqueeze(0)\n",
    "        input_y = torch.stack(a,dim=0).unsqueeze(0)\n",
    "        # Predict bandits\n",
    "        _, pred = model(input_x.to(device),input_y.to(device))\n",
    "        selected_bandit = torch.argmax(pred[-1,-1,:])\n",
    "        selected_bandits.append(selected_bandit)\n",
    "        a.append(nn.functional.one_hot(selected_bandit,num_classes=a_num).float().to(device))\n",
    "        # new_r = reward_function(new_s,a[-1].detach().cpu(),theta,Ms,Ma)\n",
    "        new_r = theta@Ma@(a[-1].detach().cpu())\n",
    "        # print(selected_bandit)\n",
    "        \n",
    "    return bandit_values, optimal_value, worst_value, selected_bandits\n",
    "\n",
    "def rank(avg_r, r_list):\n",
    "    for i in range(len(r_list)):\n",
    "        if avg_r < r_list[i]:\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73bb0d8a-5ed8-4ddc-8bd5-b7330de9f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg return: 0.012679548934102058\n",
      "best return: 0.05268328636884689\n",
      "worst return: -0.05264483764767647\n"
     ]
    }
   ],
   "source": [
    "bandit_values,optimal_value, worst_value, bandits = test_model(adapter,horizon=150)\n",
    "print('avg return:', np.average([bandit_values[b.detach().cpu().item()].item() for b in bandits[50:]]))\n",
    "print('best return:', optimal_value)\n",
    "print('worst return:', worst_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f38d83c-c939-4b75-83c3-e0dbfa63cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0526, -0.0382, -0.0016,  0.0127,  0.0527])\n",
      "[4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(torch.sort(bandit_values)[0])\n",
    "print([b.item() for b in bandits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a78964-4efc-4829-a853-dcde7dccfb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02042222023010254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869f6a32ce54cbd92f7e3c511ec3e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranks = []\n",
    "regrets = []\n",
    "opt_values = []\n",
    "worst_values = []\n",
    "selected_bandits = []\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    bandit_values,optimal_value, worst_value, bandits = test_model(adapter,horizon=150)\n",
    "    avg_return = np.average([bandit_values[b.detach().cpu().item()].item() for b in bandits[100:]])\n",
    "    regrets.append(optimal_value-avg_return)\n",
    "    opt_values.append(optimal_value)\n",
    "    worst_values.append(worst_value)\n",
    "    selected_bandits.append([b.item() for b in bandits])\n",
    "    ranks.append(rank(avg_return, torch.sort(bandit_values)[0])/5)\n",
    "    # print([b.item() for b in bandits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c9a6d-6365-43e8-9bd1-cdea6d726212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the performance metric: regret/(optimal_value - worst_value)\n",
    "# 0 is best, 1 is worst\n",
    "np.array(regrets)/(np.array(opt_values) - np.array(worst_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcae07d-d3ec-4709-b913-653a289dac42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Legacy Code (Ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8cf57e44-77b8-4476-bb0e-3445b2d14849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00489044189453125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64925c308fac4647ad436300af9c0637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8020, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8295, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8209, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8258, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8092, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8200, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8119, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8075, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8362, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8214, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8175, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8261, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8110, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8223, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8019, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8150, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8008, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8072, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8030, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.7988, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8156, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.7946, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.7940, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.8043, device='cuda:1', grad_fn=<DivBackward1>)\n",
      "tensor(1.7943, device='cuda:1', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "loss = nn.CrossEntropyLoss() # cross-entropy loss for bandit identification\n",
    "optimizer = torch.optim.Adam(adapter.parameters(),lr=1e-4)\n",
    "\n",
    "EPOCHS = 5000\n",
    "total_num = ICL_X.shape[0]\n",
    "batch_size = 8\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    optimizer.zero_grad()\n",
    "    indices = np.random.choice(range(total_num),batch_size,replace=False)\n",
    "    batch_x = ICL_X[indices]\n",
    "    batch_y = ICL_Y[indices]\n",
    "\n",
    "    _,pred = adapter(batch_x.to(device),batch_y.to(device))\n",
    "    pred_bandit = torch.argmax(pred,dim=-1)\n",
    "    l = loss(pred[:,:,:].softmax(dim=-1), batch_y[:,:,:].to(device))\n",
    "\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200 == 0:\n",
    "        # print('selected bandits:',pred_bandit)\n",
    "        print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f1022477-f7ec-49d7-85bb-4ce653e5a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adapter, '../models/less_naive_adapter.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "36846050-ae52-438a-bed3-654550200e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -5.2011,   1.6482,  -6.3739,  -0.1427,  -6.1827,  -9.7138,  -0.3569,\n",
       "          6.4348,  -0.3145,  -5.9095,   3.1633,   2.1572,  -1.6072,   0.2380,\n",
       "         -0.5632,  -1.2888,   7.2966,   2.7758,  -2.2375,  -2.5067,   1.3271,\n",
       "         -0.0910,  -8.4142,   8.3373, -11.8403,  -2.1347,  -2.4112,   7.2236,\n",
       "         -2.5696,  -7.2637,  -0.9239,   4.3019,  -0.2706,  -1.3537,  -0.7677,\n",
       "         -3.6587,   2.4505,  -2.4339,   1.2420,   4.9552,   5.1487, -10.6287,\n",
       "         -0.6562,   5.0139,   3.0126,   1.6920,  -3.0392,  -9.6241,  -1.6161,\n",
       "          6.0712,   1.4880,  -2.9165,   1.6696,   0.6303,   1.3941,   4.2367,\n",
       "          5.7465,   2.1158,   6.4666,   4.7635,   2.8982,  -2.9378,  -7.0493,\n",
       "         -4.3799,   0.3168,   7.7574,   6.7376,  -4.2825,   5.0983,  -0.3487,\n",
       "         -3.3717,   5.4457,  -4.9380,   5.0232,   4.0637,  -0.6166,   5.5513,\n",
       "          4.3126,  -0.7402,  -3.0745,   3.8573,  -2.7212,   9.5248,  -6.1576,\n",
       "         -1.7650,  -1.7771,   2.0558,  -8.9426,  -8.4776,  -3.4777,   0.4516,\n",
       "          1.4756,   1.7206,  -4.6948,   0.9487,  -8.9091,  -1.9844,  -8.2671,\n",
       "         -0.5455,   2.2572])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model,input_r,horizon=100):\n",
    "    \n",
    "    selected_bandits = []\n",
    "    s=[]\n",
    "    new_a = torch.distributions.categorical.Categorical(torch.tensor([1/a_num]*a_num)).sample()\n",
    "    new_a = nn.functional.one_hot(new_a,num_classes=a_num).float().to(device)\n",
    "    a=[new_a] #dummy first action\n",
    "    r=[] \n",
    "    \n",
    "    for _ in range(horizon):\n",
    "        # encounter a new state\n",
    "        new_s = torch.randn(s_dim)\n",
    "        s.append(new_s)\n",
    "        r.append(torch.tensor(input_r))\n",
    "        # construct inputs\n",
    "        input_x = torch.cat([torch.stack(s,dim=0),torch.stack(r,dim=0).unsqueeze(-1)],dim=-1).unsqueeze(0)\n",
    "        input_y = torch.stack(a,dim=0).unsqueeze(0)\n",
    "        # Predict bandits\n",
    "        _, pred = model(input_x.to(device),input_y.to(device))\n",
    "        selected_bandit = torch.argmax(pred[-1,-1,:])\n",
    "        selected_bandits.append(selected_bandit)\n",
    "        a.append(nn.functional.one_hot(selected_bandit,num_classes=a_num).float().to(device))\n",
    "        # print(selected_bandit)\n",
    "        \n",
    "    return selected_bandits\n",
    "\n",
    "bandit_values = theta@Ma\n",
    "bandit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a22d9af4-22a3-4c27-8b9c-cf6ef5d12807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.8403, -10.6287,  -9.7138,  -9.6241,  -8.9426,  -8.9091,  -8.4776,\n",
       "         -8.4142,  -8.2671,  -7.2637,  -7.0493,  -6.3739,  -6.1827,  -6.1576,\n",
       "         -5.9095,  -5.2011,  -4.9380,  -4.6948,  -4.3799,  -4.2825,  -3.6587,\n",
       "         -3.4777,  -3.3717,  -3.0745,  -3.0392,  -2.9378,  -2.9165,  -2.7212,\n",
       "         -2.5696,  -2.5067,  -2.4339,  -2.4112,  -2.2375,  -2.1347,  -1.9844,\n",
       "         -1.7771,  -1.7650,  -1.6161,  -1.6072,  -1.3537,  -1.2888,  -0.9239,\n",
       "         -0.7677,  -0.7402,  -0.6562,  -0.6166,  -0.5632,  -0.5455,  -0.3569,\n",
       "         -0.3487,  -0.3145,  -0.2706,  -0.1427,  -0.0910,   0.2380,   0.3168,\n",
       "          0.4516,   0.6303,   0.9487,   1.2420,   1.3271,   1.3941,   1.4756,\n",
       "          1.4880,   1.6482,   1.6696,   1.6920,   1.7206,   2.0558,   2.1158,\n",
       "          2.1572,   2.2572,   2.4505,   2.7758,   2.8982,   3.0126,   3.1633,\n",
       "          3.8573,   4.0637,   4.2367,   4.3019,   4.3126,   4.7635,   4.9552,\n",
       "          5.0139,   5.0232,   5.0983,   5.1487,   5.4457,   5.5513,   5.7465,\n",
       "          6.0712,   6.4348,   6.4666,   6.7376,   7.2236,   7.2966,   7.7574,\n",
       "          8.3373,   9.5248])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(bandit_values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3f991e83-21b8-4cb9-a607-4f6352a8b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_r:0.0 rewards -1.1543026 0.17061827\n",
      "input_r:10.0 rewards 0.24711378 0.28390676\n",
      "input_r:20.0 rewards 2.7497773 0.24683237\n",
      "input_r:100.0 rewards 5.7336683 0.007939255\n",
      "input_r:250.0 rewards 0.34360862 0.04985754\n",
      "input_r:500.0 rewards -2.5695734 0.0\n"
     ]
    }
   ],
   "source": [
    "for input_r in [0.,10.,20.,100.,250.,500.]:\n",
    "    runs = []\n",
    "    for _ in range(5):\n",
    "        bandits = test_model(adapter,input_r=input_r,horizon=50)\n",
    "        # print([b.detach().cpu().item() for b in bandits])\n",
    "        avg_rewards = np.average([bandit_values[b.detach().cpu().item()] for b in bandits])\n",
    "        runs.append(avg_rewards)\n",
    "    print(f'input_r:{input_r}', 'rewards', np.average(runs),np.var(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "140fd9c2-dcda-40aa-8e8f-6e0b63273454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4794e+00,  6.9455e+00, -1.6326e+01, -3.7359e+00,  1.2556e+01,\n",
       "         2.4965e+01,  8.7280e+00, -1.4675e+01, -1.1836e+01, -9.5921e+00,\n",
       "         1.8663e+01,  2.5561e+01, -2.2740e+01,  9.0587e-01,  9.7514e-01,\n",
       "         2.9755e+01, -7.8016e+00,  7.1111e+00, -2.7794e+00,  1.0005e+01,\n",
       "         1.3468e+01,  2.1822e+00,  4.7645e+00,  7.4162e+00, -1.7447e+01,\n",
       "        -1.2855e+01,  1.2345e+01, -6.2606e+00,  5.2475e+00, -1.2295e+01,\n",
       "         1.9056e+01, -1.6313e+01, -5.5074e+01,  4.4581e+01,  1.6872e+01,\n",
       "         1.5547e+01,  4.0048e+00,  2.5713e+01, -1.5063e+01,  9.1060e+00,\n",
       "        -3.3305e+00,  2.9580e-01,  1.3879e+01, -1.4045e+01, -7.4136e+00,\n",
       "         2.2452e+01,  1.3520e+01, -2.2897e+01, -2.7340e+01, -5.0949e+00,\n",
       "         7.9965e+00,  1.2841e+01, -3.5550e+01, -2.8889e+00,  7.4625e+00,\n",
       "        -1.1878e+01, -9.6043e+00,  3.5396e+01,  2.1978e+00,  2.1904e+01,\n",
       "         1.7308e+01,  7.2392e+00,  8.1534e+00, -1.8541e+01,  4.0366e+00,\n",
       "        -1.4968e+01, -2.2632e+01,  2.2521e+00,  1.2594e+00, -1.6477e+01,\n",
       "        -9.7953e+00, -5.1913e+00, -9.7035e+00, -6.8443e-01, -5.6467e+00,\n",
       "        -7.1515e+00,  2.7737e+00,  1.0730e+01, -1.2887e+01,  1.3718e+01,\n",
       "        -1.5825e+01,  1.5955e+01, -8.9051e+00,  2.0719e+01,  1.2108e+01,\n",
       "         1.7711e+01, -6.1778e+00, -7.8071e-01, -2.2193e+01, -2.5289e+00,\n",
       "         1.1339e+01,  1.0282e+01,  3.2343e+00,  1.7862e+01,  4.2366e+01,\n",
       "        -1.1510e+01,  1.4934e+01, -4.5786e+00, -1.7353e+01, -2.6250e+01,\n",
       "        -3.3073e-01,  2.6304e+01,  5.9841e+00,  2.1837e+01,  5.8467e+00,\n",
       "        -1.4814e+01, -1.9223e-01,  1.7440e+01, -1.1576e+01, -9.5864e+00,\n",
       "        -2.5565e+01, -1.0529e+01, -2.7926e+01,  2.2084e+01,  9.3164e+00,\n",
       "         7.1503e+00, -2.7311e+01, -2.8246e+01, -1.4180e+01, -1.3542e+01,\n",
       "         7.9741e+00,  1.2394e+01, -2.0861e+01,  2.7030e+01,  7.5767e+00,\n",
       "         2.8080e+01,  6.9997e+00,  2.6399e+00, -6.0158e+00,  2.2559e+01,\n",
       "        -6.3000e+00, -1.5632e+01,  1.4837e+01, -2.0226e+00,  2.2220e+01,\n",
       "        -8.2089e+00,  1.5797e+01, -1.0020e+01, -8.6945e+00, -1.7427e+00,\n",
       "        -1.9983e+01,  1.4070e+01,  7.3310e+00,  4.9990e+00, -4.0426e+01,\n",
       "        -1.2723e+01,  1.8217e+01, -8.1755e+00,  1.7169e+01,  3.8246e+01,\n",
       "         7.1460e-01, -1.1632e+01, -1.8939e+01,  2.6946e+01, -2.4337e+01,\n",
       "         2.8098e+01, -3.5078e+00,  5.5270e+00,  9.7162e+00,  1.3597e+01,\n",
       "         3.5573e+00,  1.6374e+01,  7.5609e+00,  3.7986e-01,  1.1437e+01,\n",
       "        -1.0957e+01, -3.0695e+01,  1.0978e+01, -1.2782e+01,  1.8515e+00,\n",
       "        -9.8183e+00, -3.2437e+00, -4.1476e+01, -2.5837e+01, -4.8671e+00,\n",
       "         3.3090e+01,  1.3142e+01,  1.9443e+00,  8.9004e-01,  8.0101e-01,\n",
       "         9.8563e+00, -1.1792e+01,  3.7098e+00, -1.4244e+01,  2.8207e+00,\n",
       "         8.4210e-02,  3.0844e-01,  1.7876e+01, -1.1115e+01,  2.5088e+01,\n",
       "        -3.9948e+00, -1.6870e+01,  1.2597e+01, -1.7057e+01,  6.7064e+00,\n",
       "        -2.3708e+00,  1.7799e+01,  7.5868e+00,  3.0175e+01,  1.6179e+01,\n",
       "        -2.4036e+00, -4.0735e+01,  3.7344e+01, -3.9084e+01,  2.2455e+01,\n",
       "         2.9012e+00, -1.8576e+01,  2.6304e+00,  5.8866e+00, -2.6853e+00,\n",
       "         2.5212e+01, -3.5544e+00, -1.4257e+01,  8.4381e+00, -1.2285e+01,\n",
       "         1.4650e+01, -1.2915e+01,  1.8124e+01, -1.9931e+00, -1.7990e+01,\n",
       "        -1.0573e+01,  1.1508e+01,  5.9957e+00, -1.1608e+01,  1.4814e+01,\n",
       "        -4.6620e+00,  7.3884e+00,  1.6558e+01,  1.1017e+00,  1.3042e+01,\n",
       "        -4.4508e+00, -2.1781e+01, -4.6614e+00,  1.1485e+01,  1.0846e+01,\n",
       "        -1.4262e+01, -3.1749e+00,  7.0125e+00, -6.0355e+00,  2.3022e+01,\n",
       "        -3.4703e+00,  2.1384e+01,  2.4624e+01,  1.5378e+01,  1.3887e+01,\n",
       "        -2.9397e+01,  1.7000e+01,  3.0114e+00,  1.8516e+01, -9.9110e+00,\n",
       "        -1.7471e+01,  1.0463e+01, -1.6978e+01,  3.7002e+00, -1.0492e+01,\n",
       "        -6.4538e+00,  1.1361e+00,  2.4786e+01, -7.7541e+00,  1.4165e+01,\n",
       "        -1.2951e+01, -1.0737e+01,  3.0628e+01, -2.1724e+01,  2.2175e+01,\n",
       "        -2.5905e+01, -2.8055e+01, -5.3501e-04,  1.2862e+00, -6.1174e+00,\n",
       "         5.2260e+00, -9.1702e+00,  8.5467e+00, -4.6024e+01, -8.7239e+00,\n",
       "        -9.1225e+00, -1.6041e+01,  4.2513e+01,  1.1321e+01,  1.5543e+01,\n",
       "         9.5132e-01,  1.8976e+01,  3.8000e+01, -2.1605e+01,  1.7752e+01,\n",
       "         6.9559e+00, -3.6075e+00,  8.2476e+00, -5.0576e+00, -1.8760e+01,\n",
       "        -1.8323e+01,  5.5779e+00,  1.1364e+00, -1.8477e+00, -2.0304e+01,\n",
       "         2.0053e+00,  1.4275e+01,  5.3234e+00, -2.6473e+01, -6.2137e+00,\n",
       "         4.1742e+00, -1.3955e+01, -3.0504e+00,  1.4240e+01, -1.5222e+01,\n",
       "        -1.5368e+01, -1.0719e+01, -1.5890e+01,  2.0575e+01, -3.8799e+00,\n",
       "        -1.5573e+00, -2.9603e+01, -4.1951e+00,  2.3569e+01,  1.4820e+01,\n",
       "         1.1628e+00,  1.0723e+01,  8.8484e+00,  1.4437e+01, -1.5829e+01,\n",
       "         3.2830e+00, -2.5885e+01,  1.8385e+01,  2.7919e+01, -2.5419e+01,\n",
       "         1.0117e+01, -1.0319e+01, -2.0576e+01,  2.9887e+01,  6.7305e+00,\n",
       "         1.3572e+01,  2.0359e+01,  1.1135e+01, -2.2412e+01,  7.4586e+00,\n",
       "        -1.5445e+01,  9.5278e+00, -5.2297e+01, -1.3063e+01, -3.8069e+00,\n",
       "        -1.7950e+01,  2.0072e+01,  2.0240e+01, -1.7066e+00,  1.2870e+01,\n",
       "         1.3756e+00, -9.7853e-01,  8.8972e+00,  3.6051e+01,  3.7177e+00,\n",
       "        -4.5337e+00, -2.8688e+01,  6.8450e+00, -1.4275e+01, -1.5750e+01,\n",
       "        -4.0840e+00, -2.4350e+01, -3.2492e+01,  3.1976e+01,  4.4490e+01,\n",
       "         6.8431e+00,  6.6041e+00,  9.4107e+00, -1.1469e+01, -1.9379e+00,\n",
       "        -9.5002e+00,  2.8963e+00,  3.0676e+00, -1.8551e+01, -5.1669e+00,\n",
       "         1.5976e+01,  1.5266e+01, -4.6509e+00,  9.6590e+00, -1.7300e+00,\n",
       "        -1.6941e-01,  3.0866e+00,  1.9252e+00, -3.3321e+00,  1.6967e+00,\n",
       "         1.0587e+01,  1.3644e+01,  2.0628e+01, -1.1789e+00,  1.2406e+00,\n",
       "        -1.0040e+01,  3.0802e+01, -1.9938e+01, -1.4274e+01,  1.5076e+01,\n",
       "         1.2417e+01,  5.8088e+00, -2.5106e+01, -8.1767e+00, -1.2537e+01,\n",
       "         4.9271e+00, -1.2608e+00,  3.8817e+01,  1.5777e+01,  1.1043e+01,\n",
       "        -1.8509e+01,  2.6156e+01, -1.6264e+00,  1.4845e+01,  2.8718e+00,\n",
       "        -3.7748e+00,  1.6557e+00, -3.1501e+01, -3.3109e+00,  1.6106e+00,\n",
       "         6.7642e+00, -2.6153e+01, -1.3468e+01, -6.2010e+00, -1.1645e+01,\n",
       "        -1.3579e+01, -4.8847e+00,  7.4571e+00,  2.1611e+01, -2.6010e+01,\n",
       "        -2.4088e+00, -9.4310e+00, -3.1566e+00,  1.2717e+01,  1.5463e+01,\n",
       "        -1.7768e+00, -1.3265e+01,  4.9713e+00,  1.3410e+01,  2.5163e+01,\n",
       "        -1.3041e+00,  1.7005e+00, -2.9612e+01, -2.3050e+01, -1.7756e+01,\n",
       "        -5.9603e+00,  1.2724e+01,  7.6708e+00, -3.5098e+01, -1.6050e+01,\n",
       "         3.3091e+00, -5.7898e+00, -3.1382e+01, -4.9966e+01,  3.6925e+01,\n",
       "        -2.0968e+00, -3.6094e+00, -5.3147e+00,  3.5362e+00, -2.7569e+01,\n",
       "        -1.0208e+01,  1.5674e+01,  3.6609e+00, -9.9234e+00,  2.1886e+01,\n",
       "        -3.2746e+01, -2.1077e+00,  5.1361e-01,  7.0569e+00,  1.4468e+00,\n",
       "         6.4881e+00,  5.5357e+00, -1.1774e+01,  5.3944e+00, -1.2872e+01,\n",
       "        -2.8821e+01,  1.6461e+01, -3.5447e+00,  1.9863e+01, -1.2998e+01,\n",
       "        -9.0604e+00, -3.6294e+01, -8.6208e+00,  6.5700e+00, -2.1681e+00,\n",
       "        -1.3720e+01, -2.3743e+01, -9.6581e-02,  3.6841e+00,  1.8255e+01,\n",
       "        -1.6415e+01, -2.1901e+01, -6.7799e+00,  4.2797e+00, -1.5206e+01,\n",
       "        -2.0508e+00,  8.4975e+00, -1.4937e+01, -2.5828e+01,  1.3035e+01,\n",
       "        -2.1455e+01, -1.9470e+01, -2.7824e+01,  1.7711e+01, -2.3651e+01,\n",
       "         1.7057e+01,  1.5254e+01, -1.4019e+01, -1.0560e+01,  3.5969e+00,\n",
       "        -1.1260e+01,  1.1661e+01, -2.2297e+01,  3.1077e+01,  6.9465e+00,\n",
       "         2.3876e+01,  1.2080e+01,  2.5097e+00, -6.1528e+01, -8.0787e+00,\n",
       "         2.7982e+01, -2.5489e+01,  1.5067e+01,  1.1713e+01, -2.1676e+01,\n",
       "         4.6904e+01, -3.7187e+00, -8.1017e+00,  1.1337e+01,  2.8605e+01,\n",
       "         9.6221e+00,  3.6200e+01, -4.5316e+00, -2.2929e+01,  9.6987e+00,\n",
       "         1.0969e+01,  8.5997e+00, -4.4594e+00, -1.5288e+00,  3.6430e+01,\n",
       "         7.1069e+00,  1.0121e+01, -1.7896e+01,  1.8611e+01, -6.1465e+00,\n",
       "        -8.4536e+00, -2.1421e+01, -1.7229e+00, -3.1293e+01, -2.5007e+01,\n",
       "        -2.4443e+01, -4.4373e+00,  3.9551e+01,  1.8178e+01, -1.6304e+01,\n",
       "         1.2733e-01,  1.8798e+01, -5.1579e-01,  1.9483e+01, -1.0511e+01,\n",
       "        -9.2176e+00, -5.1237e+00,  7.1059e+00, -4.3203e+01,  3.3959e+01,\n",
       "         2.4843e+01, -1.5543e+01, -1.7238e+01,  1.0862e+01, -2.7485e+01,\n",
       "         2.6101e+00,  2.8470e+01, -3.5462e+00,  2.9697e+01,  7.8964e+00,\n",
       "        -6.8734e+00, -1.1224e+01, -1.1329e+01, -2.0431e+01,  2.4954e+00,\n",
       "         1.7616e+01,  1.1392e+01,  1.1731e+00,  6.4965e+00,  2.6627e+01,\n",
       "        -2.1513e-01, -1.0077e+01, -5.5765e+00, -1.5513e+01, -6.4427e+00,\n",
       "         1.5837e+01, -9.6186e+00,  1.7150e+01, -4.0213e+00,  1.8947e+01,\n",
       "         1.5437e+00, -3.5553e+01, -8.6285e+00,  2.8930e+01, -3.8336e+01,\n",
       "         2.5395e+01,  3.6039e+00,  1.5487e+01, -1.2353e+01,  2.9091e+00,\n",
       "         2.5070e+01,  1.2607e+01, -1.3170e-03,  4.0257e-01,  6.7855e+00,\n",
       "        -3.0193e+00, -1.3651e+01, -3.8091e+00, -6.1300e+00,  1.6603e+01,\n",
       "        -2.2526e+01,  3.1272e+01, -7.2400e+00, -8.0265e+00, -1.1018e+01,\n",
       "         5.1005e+00,  2.9091e+00, -3.2023e+00,  1.5686e+01, -2.1044e+01,\n",
       "        -7.1149e+00, -8.0760e+00, -4.1655e+00, -1.3805e+01, -1.1032e+01,\n",
       "        -1.0525e+00,  1.1140e+01, -1.2572e+00, -1.4400e+01,  1.8358e+01,\n",
       "        -2.2037e+01, -1.1416e+00, -7.4135e-01,  4.7102e-01,  3.4219e+01,\n",
       "        -1.6442e+01, -4.5659e+01, -5.8061e+00, -2.4804e+01,  2.0395e+01,\n",
       "         4.1079e+00,  1.1382e+01,  2.0756e+01, -1.8893e+01, -1.8914e+01,\n",
       "        -2.6755e+01,  2.5559e+01, -2.3281e+01, -2.5232e+01, -3.2492e+00,\n",
       "        -1.2514e+01,  2.1923e+00,  4.8612e+00, -1.2876e+01,  6.4896e+00,\n",
       "         8.7117e+00, -1.4687e+01,  7.2527e+00,  2.6978e+00, -1.6941e+01,\n",
       "        -1.5440e+01, -2.2195e+01, -8.6902e+00, -8.1417e+00, -1.9575e+01,\n",
       "         5.3431e+00,  1.0580e+01, -2.3876e+01, -1.2041e+01, -2.5070e+01,\n",
       "        -4.5054e+00, -2.0783e+01,  7.4321e+00, -2.6935e+01, -3.5907e-01,\n",
       "        -1.0176e+00,  4.1403e-01, -2.4227e+01, -3.5764e+01, -1.4573e+01,\n",
       "        -1.1017e+01, -4.2244e+01, -5.3588e-01, -1.7288e+01,  1.5058e+01,\n",
       "        -2.8272e+01,  1.0370e+01,  5.3349e+00,  2.8883e+01,  7.9846e+00,\n",
       "         2.8239e+01,  1.9772e+01, -2.4380e+01,  1.4569e+01, -7.9793e+00,\n",
       "         2.8276e+01,  1.4959e+01, -5.9041e+00, -5.4576e+00, -1.4088e+01,\n",
       "        -5.9386e+00,  1.4774e+00,  4.7921e+00,  4.2931e+00,  3.9706e+01,\n",
       "         2.2558e+01,  2.5903e+01,  1.4003e+01,  8.8466e+00,  4.0244e+00,\n",
       "        -1.0170e+01,  8.2715e+00,  2.9707e+00,  1.9829e+01,  5.0522e+00,\n",
       "        -6.6260e+00, -4.5967e+00, -1.6094e+01, -2.9620e+01,  2.1645e+01,\n",
       "        -5.2015e+00,  9.6168e-01,  7.4724e+00, -9.8156e+00, -2.2569e+00,\n",
       "         2.1310e+00,  2.0049e+01, -6.9000e+00,  6.2848e+00, -2.2100e+01,\n",
       "         1.9755e+00, -2.2980e+01,  2.8876e+01,  9.4367e+00,  5.7225e-01,\n",
       "        -1.0865e+01, -2.5601e+01, -1.5477e+01, -5.1420e+00,  7.1452e+00,\n",
       "         1.3868e+01, -1.4306e+01,  6.3600e+00,  6.0048e+00, -1.3629e+00,\n",
       "        -1.1901e+01, -1.4113e+01, -5.0067e+00,  3.0454e+01, -3.7596e+01,\n",
       "         1.4762e+01,  5.4582e+00,  5.2182e+00,  5.9139e-01,  1.0676e+01,\n",
       "         5.6090e+00, -2.0430e+01, -2.7425e+01,  2.9266e+01, -2.9990e+01,\n",
       "        -1.8308e+01,  2.4379e+01, -4.9550e+01, -2.1594e+00, -1.9975e+01,\n",
       "        -9.1764e+00,  1.1520e+01, -6.1162e+00,  4.4038e+00, -3.8367e+00,\n",
       "         1.8410e+01,  2.3621e+01,  1.2078e+01,  3.6930e+01,  9.6012e+00,\n",
       "        -1.4294e-01, -2.3962e+00,  3.5093e+00,  2.3472e+01,  9.0513e+00,\n",
       "        -1.2304e+01,  2.4123e+01, -1.0437e+01,  7.1858e+00, -9.6982e+00,\n",
       "         4.1937e+01, -6.5888e+00, -2.2723e+01, -2.4904e+01, -2.9603e+00,\n",
       "        -1.4768e+00,  1.7075e+01, -1.2057e+01, -2.5692e+01,  5.2570e+00,\n",
       "         2.9266e+01,  1.1274e+01,  6.4590e+00, -1.9608e+01,  8.9665e+00,\n",
       "        -1.5915e+01,  4.1116e+01, -1.6102e+01,  3.0559e+01,  5.7658e+00,\n",
       "        -7.5773e+00, -6.7941e+00,  2.2375e+01, -3.1185e+00,  2.7180e+01,\n",
       "         1.5659e+01,  2.8059e+01, -1.1515e+01, -7.4265e+00, -2.1212e+00,\n",
       "        -1.4295e+01, -5.2386e+00, -4.1153e+01, -1.4497e+01, -3.2999e+01,\n",
       "         3.1123e+01, -2.4216e+01, -1.0005e+01,  3.1667e+00, -4.0887e+01,\n",
       "         2.1972e+01,  3.0543e+01, -1.2803e+00,  1.2327e+01,  1.9363e+00,\n",
       "         2.4718e+00, -4.6464e+01, -9.3836e+00, -1.5786e+01,  2.7643e+00,\n",
       "         1.1524e+01, -1.1230e+01,  4.3602e+00,  2.1769e+01, -2.2595e+01,\n",
       "        -5.7575e+00, -1.5725e+01, -1.2512e+01,  1.7945e+01, -2.0591e+01,\n",
       "         1.1571e+01,  2.6357e+00, -3.7143e+01, -3.0528e+01, -1.1964e+01,\n",
       "        -9.3017e+00,  3.0301e+01,  1.8521e+01, -8.5594e+00,  6.8832e+00,\n",
       "         1.9894e+01,  5.6352e+00,  4.6676e+01,  8.0558e+00, -1.9167e+01,\n",
       "        -6.7848e+00,  2.2942e+01,  1.5672e+01,  1.2296e+00,  1.0040e+01,\n",
       "        -1.0265e+01,  1.1362e+01, -1.0928e+00, -6.8938e+00,  4.8504e+00,\n",
       "         8.7241e+00, -1.1054e+01, -9.4189e+00, -7.8910e+00,  1.8625e+01,\n",
       "        -2.0860e+01,  1.3729e+01,  1.1571e+01, -2.8212e+01,  1.1192e+00,\n",
       "         7.1267e+00, -1.1575e+01, -1.6349e+01, -1.0930e+01,  3.3075e+00,\n",
       "        -1.4144e+01, -1.3771e+01,  4.4175e+00,  5.9539e-01, -1.2360e+00,\n",
       "         1.3327e+01, -4.8532e+00, -1.3616e+01, -1.9573e+01, -2.8543e+01,\n",
       "        -1.8170e+01,  1.6508e+01, -3.7798e+00,  3.7880e+01,  2.2122e+01,\n",
       "        -9.3642e+00,  1.6316e+00, -9.5717e-01, -4.9455e+00, -3.7032e+01,\n",
       "        -1.2088e+01, -1.4960e+01,  8.0464e+00,  6.2277e-01,  5.2091e+00,\n",
       "         3.2666e+00,  4.2601e+00, -1.3805e+01,  5.2846e+00,  3.5085e-01,\n",
       "        -1.9211e+01, -2.3929e+00, -1.5852e+01, -3.0486e+01,  2.5174e+00,\n",
       "         2.0150e+01,  3.3072e+01, -9.3473e+00, -1.7890e+01,  3.8808e+00,\n",
       "        -2.0517e+01, -6.0446e+00, -8.5424e+00,  1.4910e+01,  1.1068e+01,\n",
       "         1.8719e+01,  3.0523e+01,  5.3494e+00,  8.2861e+00,  2.4544e+01,\n",
       "         9.4221e+00,  1.0827e+01,  2.1338e+01,  1.8654e+01, -6.8553e+00,\n",
       "         1.9684e+01, -8.9231e-01,  4.4255e+00, -1.8807e+00, -2.1082e+01,\n",
       "        -9.6569e+00, -8.1017e+00, -1.7902e+01, -2.6687e+01,  8.1263e-01,\n",
       "        -2.1643e+01,  1.0205e+01,  9.4169e+00, -1.1251e+01,  7.9675e+00,\n",
       "         1.5991e+01, -1.5437e+01, -1.3989e+01, -1.5928e+01, -6.8757e+00,\n",
       "        -2.2744e+01,  4.6804e+00, -2.1529e+01,  1.6860e+01,  2.8689e+01,\n",
       "        -1.2887e+01, -2.2230e+01, -9.9521e+00,  7.7234e+00, -1.6086e+01,\n",
       "        -2.7591e+01,  1.6921e+01,  2.1501e+01, -3.0640e+00, -2.1172e+00,\n",
       "         1.9205e+01, -1.5455e+01, -3.9771e+00,  4.7756e+01, -2.8417e+01,\n",
       "         9.2635e+00,  9.3130e+00,  1.2326e+01, -5.5252e-01, -8.1435e+00,\n",
       "         5.8906e+00,  2.0313e+01, -7.4359e+00,  1.9001e-01, -1.1266e+01,\n",
       "         1.8726e+01,  1.7596e+01,  6.6874e+00, -3.5454e+01,  1.1908e+01,\n",
       "         1.3626e+01,  2.7154e+01,  2.2160e+01, -2.4969e+01,  1.0287e+01,\n",
       "         8.2645e+00,  6.8367e+00, -4.1747e+00,  9.1607e+00, -3.6654e+01])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d8ac43d0-f9d9-4553-b42f-25f4bee851a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1'),\n",
       " tensor(28, device='cuda:1')]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4efa1-6c10-4bfa-bc10-3484228c24f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-learning",
   "language": "python",
   "name": "in-context-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
